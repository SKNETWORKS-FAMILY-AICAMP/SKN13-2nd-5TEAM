# app.py íŒŒì¼
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from utils.data_processor import load_and_process_data
from components.model_selector import get_model
from components.model_evaluator import evaluate_model  # ìˆ˜ì •ëœ evaluate_model ê°€ì ¸ì˜¤ê¸°
from components.model_compare import compare_models

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")
st.title("ğŸ“Š ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°” ë©”ë‰´
menu_selection = st.sidebar.selectbox(
    "ğŸ“Œ ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”",
    ["ëª¨ë¸ ë¹„êµ", "ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ë¹„êµ"]
)

# ğŸ” X_train.csv ì—†ìœ¼ë©´ ì „ì²˜ë¦¬ ë¨¼ì € ìˆ˜í–‰ 
if not os.path.exists('data/processed/X_train.csv'):
    load_and_process_data()

# ë°ì´í„° ë¡œë“œ
X_train = pd.read_csv('data/processed/X_train.csv')
X_test = pd.read_csv('data/processed/X_test.csv')
y_train = pd.read_csv('data/processed/y_train.csv')
y_test = pd.read_csv('data/processed/y_test.csv')

# ëª¨ë¸ ëª©ë¡
model_names = [
    'Logistic Regression', 'Random Forest', 'Gradient Boosting', 'SVM', 'XGBoost'
]

# 1. ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ë¹„êµ ë©”ë‰´
if menu_selection == "ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ë¹„êµ":
    st.title("ğŸ“ˆ ê¸°ë³¸ ëª¨ë¸ vs íŠœë‹ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ë¹„êµ")

    with st.spinner("ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
        comparison_df = compare_models(X_train, y_train.values.ravel(), X_test, y_test)

    st.subheader("ëª¨ë¸ ë¹„êµ ê²°ê³¼")
    st.dataframe(comparison_df)

    st.subheader("ğŸ“Š í–¥ìƒë¥  ì‹œê°í™”")
    fig, ax = plt.subplots(figsize=(8, 5))
    comparison_df.plot(x='Metric', y='Improvement (%)', kind='bar', legend=False, ax=ax, color='green')
    # í•œê¸€ê¹¨ì§ ã„¹ã…‡ 
    ax.set_title("Improvement (%)")
    ax.set_ylabel("Improvement (%)")
    st.pyplot(fig)

# 2. ëª¨ë¸ë³„ ì„±ëŠ¥ í‰ê°€ ë©”ë‰´
elif menu_selection == "ëª¨ë¸ ë¹„êµ":
    st.sidebar.title("ëª¨ë¸ ì„ íƒ")
    tabs = st.sidebar.radio("ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:", model_names)

    model = get_model(tabs)
    model.fit(X_train, y_train.values.ravel())
    
    # ìˆ˜ì •ëœ evaluate_model í•¨ìˆ˜ í˜¸ì¶œ
    metrics = evaluate_model(model, X_test, y_test)

    left_col, right_col = st.columns(2)

    with left_col:
        st.subheader(f"{tabs} model")
        st.metric(label="Accuracy", value=f"{metrics['accuracy']:.4f}")
        st.metric(label="Precision", value=f"{metrics['precision']:.4f}")
        st.metric(label="Recall", value=f"{metrics['recall']:.4f}")
        st.metric(label="F1 Score", value=f"{metrics['f1']:.4f}")

    with right_col:
        st.subheader(f"{tabs} Confusion Matrix")
        cm = metrics['confusion_matrix']
        fig, ax = plt.subplots(figsize=(5, 5))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Predicted No", "Predicted Yes"], yticklabels=["Actual No", "Actual Yes"])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        st.pyplot(fig)

    st.subheader(f"{tabs} Classification Report")
    st.text(pd.DataFrame(metrics['report']).transpose().round(2).to_string())
